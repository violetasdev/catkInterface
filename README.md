<h2>Kinect v2 Body Tracking Interface</h2>

The interface displays trajectories, skeleton data, and RGB feeds with the Kinect v2. 
This application is a product of my research in Body Tracking. 

## Goal
This research aims to design a technological solution to interpret the socially occupied space automatically by using depth cameras.

## Publications

- [V. A. L. S. Le√≥n and A. Schwering, "Detecting socially occupied spaces with depth cameras: evaluating location and body orientation as relevant social features," 2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN), 2021, pp. 1-8, doi: 10.1109/IPIN51156.2021.9662607](https://ieeexplore.ieee.org/document/9662607)

- [Sosa-Leon, V., Schwering, A., (2022). Evaluating Automatic Body Orientation Detection for Indoor Location from Skeleton Tracking Data to Detect Socially Occupied Spaces Using the Kinect v2, Azure Kinect and Zed 2i. Sensors 2022, 22, 3798. https://doi.org/10.3390/s22103798](https://doi.org/10.3390/s22103798)

## License
This project is licensed under the [MIT License](LICENSE).

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

## Disclaimer:
The functionalities are based on the tutorials available at [Kinect V02 Tutorial (2015)](http://kinect.github.io/tutorial/) and the Microsoft SDK samples for the Kinect V2.
